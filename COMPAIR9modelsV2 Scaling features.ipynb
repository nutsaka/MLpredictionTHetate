{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn import ensemble\n",
    "import mpl_toolkits\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "import numpy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"D:\\\\2. Project Python\\\\MLpython\\\\output.xlsx\", encoding = \"ISO-8859-1\",usecols= ['index', 'Price', 'Sqm','PSM','Floor_Level','Built_Year', 'Bedroom','Bathroom', 'Sub_district', 'District', 'City'])\n",
    "df = df[['Price', 'Sqm','PSM','Floor_Level','Built_Year', 'Bedroom','Bathroom', 'Sub_district', 'District', 'City']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Bathroom\"]] = df[[\"Bathroom\"]].astype('float64')\n",
    "# dataf[[\"Price\"]] = dataf[[\"Price\"]].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexNames2 = df[(df['Price'] <= 500000 )].index\n",
    "df = df.drop(indexNames2 , inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "    \n",
    "    # data = data.dropna()\n",
    "    data = df.drop(['City','PSM'], axis = 1)\n",
    "    # data = df.drop(['PSM'], axis = 1)\n",
    " \n",
    "    \n",
    "    # exclude everything with a price above or below 3 standard deviations (i.e. outliers)\n",
    "    data = data[np.abs(data[\"Price\"]-data[\"Price\"].mean())<=(0.3*data[\"Price\"].std())]\n",
    "    data = data[np.abs(data[\"Sqm\"]-data[\"Sqm\"].mean())<=(3*data[\"Sqm\"].std())]\n",
    "    data = data[np.abs(data[\"Bedroom\"]-data[\"Bedroom\"].mean())<=(10*data[\"Bedroom\"].std())]\n",
    "    # data = data[np.abs(data[\"Bathroom\"]-data[\"Bathroom\"].mean())<=(2*data[\"Bathroom\"].std())]\n",
    "\n",
    "    # # Set x and y (dropping zipcode and rooms as latitude, longitude and surface pretty much capture the former)\n",
    "    y = data.Price\n",
    "    X = data.drop([\"Price\"], axis = 1)\n",
    "\n",
    "\n",
    "    return data, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, X, y = preprocessing(df)\n",
    "Tester = data.drop([\"Price\"], axis = 1)[:3800]\n",
    "# labeltester = data.Price[:3800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 19040 entries, 0 to 19728\nData columns (total 8 columns):\nPrice           19040 non-null int64\nSqm             19040 non-null int64\nFloor_Level     19040 non-null int64\nBuilt_Year      19040 non-null int64\nBedroom         19040 non-null float64\nBathroom        19040 non-null float64\nSub_district    19040 non-null int64\nDistrict        19040 non-null int64\ndtypes: float64(2), int64(6)\nmemory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              Price           Sqm   Floor_Level    Built_Year       Bedroom  \\\ncount  1.904000e+04  19040.000000  19040.000000  19040.000000  19040.000000   \nmean   4.407706e+06     38.899055     12.828887   2013.916754      1.118986   \nstd    3.878784e+06     16.390179      9.103823      3.299016      0.443492   \nmin    5.069600e+05     21.000000      1.000000   1985.000000      0.500000   \n25%    2.200000e+06     29.000000      6.000000   2012.000000      1.000000   \n50%    3.200000e+06     33.000000     10.000000   2014.000000      1.000000   \n75%    5.300000e+06     45.000000     19.000000   2016.000000      1.000000   \nmax    6.370000e+07    120.000000     60.000000   2024.000000      4.000000   \n\n           Bathroom   Sub_district      District  \ncount  19040.000000   19040.000000  19040.000000  \nmean       1.124475  102657.193592   1024.789391  \nstd        0.338148    1166.932274     11.514993  \nmin        1.000000  100401.000000   1004.000000  \n25%        1.000000  101701.000000   1017.000000  \n50%        1.000000  102901.000000   1026.000000  \n75%        1.000000  103401.000000   1033.000000  \nmax        3.000000  105001.000000   1050.000000  \n"
     ]
    }
   ],
   "source": [
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('NewDataSource2.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(X , y , test_size = 0.20,random_state =3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(15232, 7)\n(3808, 7)\n(15232,)\n(3808,)\n(3800, 7)\nSqm             0\nFloor_Level     0\nBuilt_Year      0\nBedroom         0\nBathroom        0\nSub_district    0\nDistrict        0\ndtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(Tester.shape)\n",
    "print(X_train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "# X_train_maxabs = max_abs_scaler.fit_transform(x_train)\n",
    "# # x_test = max_abs_scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "x_train= max_abs_scaler.fit_transform(X_train)\n",
    "x_test = max_abs_scaler.fit_transform(X_test)\n",
    "tester = max_abs_scaler.fit_transform(Tester)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(15232, 7)\n(3808, 7)\n(3800, 7)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(tester.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbModel = xgb.XGBRegressor()\n",
    "cb_model = CatBoostRegressor()\n",
    "lgbmodel = lgb.LGBMRegressor()\n",
    "LRmodel = LinearRegression()\n",
    "RFR_model = RandomForestRegressor()\n",
    "KN_model = KNeighborsRegressor()\n",
    "D3_model = DecisionTreeRegressor()\n",
    "Lasso_model = Lasso()\n",
    "GBR_model = ensemble.GradientBoostingRegressor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Learning rate set to 0.077095\n",
      "0:\tlearn: 3705529.1988425\ttest: 3704649.3123816\tbest: 3704649.3123816 (0)\ttotal: 149ms\tremaining: 2m 28s\n",
      "50:\tlearn: 1722494.0324792\ttest: 1876196.5599945\tbest: 1876196.5599945 (50)\ttotal: 434ms\tremaining: 8.07s\n",
      "100:\tlearn: 1539984.4854395\ttest: 1721124.2349407\tbest: 1721124.2349407 (100)\ttotal: 685ms\tremaining: 6.1s\n",
      "150:\tlearn: 1443314.9962675\ttest: 1655451.5372608\tbest: 1655451.5372608 (150)\ttotal: 953ms\tremaining: 5.36s\n",
      "200:\tlearn: 1355331.9921790\ttest: 1606156.1846398\tbest: 1606156.1846398 (200)\ttotal: 1.2s\tremaining: 4.76s\n",
      "250:\tlearn: 1287461.7768652\ttest: 1566287.2841319\tbest: 1566287.2841319 (250)\ttotal: 1.42s\tremaining: 4.25s\n",
      "300:\tlearn: 1231463.1528146\ttest: 1535758.2421367\tbest: 1535758.2421367 (300)\ttotal: 1.67s\tremaining: 3.87s\n",
      "350:\tlearn: 1180965.7039609\ttest: 1510442.5152676\tbest: 1510435.1022901 (347)\ttotal: 1.92s\tremaining: 3.54s\n",
      "400:\tlearn: 1141426.5284661\ttest: 1490227.1751568\tbest: 1490227.1751568 (400)\ttotal: 2.15s\tremaining: 3.21s\n",
      "450:\tlearn: 1108318.9548171\ttest: 1473420.4646521\tbest: 1473420.4646521 (450)\ttotal: 2.39s\tremaining: 2.91s\n",
      "500:\tlearn: 1078276.6866318\ttest: 1458614.9380311\tbest: 1458497.0858154 (499)\ttotal: 2.62s\tremaining: 2.61s\n",
      "550:\tlearn: 1050964.8610965\ttest: 1447646.4056196\tbest: 1447646.4056196 (550)\ttotal: 2.86s\tremaining: 2.33s\n",
      "600:\tlearn: 1025275.1966001\ttest: 1438642.3031538\tbest: 1438642.3031538 (600)\ttotal: 3.11s\tremaining: 2.06s\n",
      "650:\tlearn: 1004275.2603535\ttest: 1431025.6423835\tbest: 1431025.6423835 (650)\ttotal: 3.34s\tremaining: 1.79s\n",
      "700:\tlearn: 982549.3169221\ttest: 1423090.1620121\tbest: 1423090.1620121 (700)\ttotal: 3.57s\tremaining: 1.52s\n",
      "750:\tlearn: 966730.1474557\ttest: 1416954.1239539\tbest: 1416954.1239539 (750)\ttotal: 3.79s\tremaining: 1.26s\n",
      "800:\tlearn: 948075.0150724\ttest: 1409926.4600032\tbest: 1409926.4600032 (800)\ttotal: 4.02s\tremaining: 999ms\n",
      "850:\tlearn: 930121.9905987\ttest: 1402371.9472062\tbest: 1402371.9472062 (850)\ttotal: 4.27s\tremaining: 747ms\n",
      "900:\tlearn: 911930.7096049\ttest: 1395747.2334255\tbest: 1395747.2334255 (900)\ttotal: 4.51s\tremaining: 495ms\n",
      "950:\tlearn: 899303.8075684\ttest: 1391519.1896140\tbest: 1391483.6675620 (948)\ttotal: 4.73s\tremaining: 244ms\n",
      "999:\tlearn: 885973.9102658\ttest: 1386706.3197835\tbest: 1386706.3197835 (999)\ttotal: 4.99s\tremaining: 0us\n",
      "\n",
      "bestTest = 1386706.32\n",
      "bestIteration = 999\n",
      "\n",
      "C:\\Users\\Nutcl\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "                          learning_rate=0.1, loss='ls', max_depth=3,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                          n_iter_no_change=None, presort='auto',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "xgbModel.fit(x_train, y_train)\n",
    "cb_model.fit(x_train, y_train,\n",
    "             eval_set=(x_test, y_test),\n",
    "             use_best_model=True,\n",
    "             verbose=50)\n",
    "lgbmodel.fit(x_train, y_train)\n",
    "LRmodel.fit(x_train,y_train)\n",
    "RFR_model.fit(x_train,y_train)\n",
    "KN_model.fit(x_train,y_train)\n",
    "D3_model.fit(x_train,y_train)\n",
    "Lasso_model.fit(x_train,y_train)\n",
    "GBR_model.fit(x_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_xgb_model = xgbModel.predict(tester,output_margin=False, ntree_limit=None, validate_features=True, base_margin=None,)\n",
    "pred_test_cb_model = cb_model.predict(tester)\n",
    "pred_test_lgb_model = lgbmodel.predict(tester)\n",
    "pred_test_LR_model = LRmodel.predict(tester)\n",
    "pred_test_RFR_model = RFR_model.predict(tester)\n",
    "pred_test_KN_model = KN_model.predict(tester)\n",
    "pred_test_D3_model = D3_model.predict(tester)\n",
    "pred_test_Lasso_model = Lasso_model.predict(tester)\n",
    "pred_test_GBR_model = GBR_model.predict(tester)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "xgbModel_Accuracy - : 0.851\ncb_model_Accuracy - : 0.872\nlgb_model_Accuracy - : 0.814\nLRmodel_Accuracy - : 0.611\nRFR_model_Accuracy - : 0.841\nKN_model_Accuracy - : 0.561\nD3_model_Accuracy - : 0.774\nLasso_model_Accuracy - : 0.611\nGBR_model_Accuracy - : 0.789\n"
     ]
    }
   ],
   "source": [
    "print (f'xgbModel_Accuracy - : {xgbModel.score(x_test,y_test):.3f}')\n",
    "print (f'cb_model_Accuracy - : {cb_model.score(x_test,y_test):.3f}')\n",
    "print (f'lgb_model_Accuracy - : {lgbmodel.score(x_test,y_test):.3f}')\n",
    "print (f'LRmodel_Accuracy - : {LRmodel.score(x_test,y_test):.3f}')\n",
    "print (f'RFR_model_Accuracy - : {RFR_model.score(x_test,y_test):.3f}')\n",
    "print (f'KN_model_Accuracy - : {KN_model.score(x_test,y_test):.3f}')\n",
    "print (f'D3_model_Accuracy - : {D3_model.score(x_test,y_test):.3f}')\n",
    "print (f'Lasso_model_Accuracy - : {Lasso_model.score(x_test,y_test):.3f}')\n",
    "print (f'GBR_model_Accuracy - : {GBR_model.score(x_test,y_test):.3f}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"D:\\\\2. Project Python\\\\MLpython\\\\NewDataSource2.csv\")\n",
    "\n",
    "new_line = pd.DataFrame({\"Lasso_target\":pred_test_Lasso_model\n",
    "                            ,'XGB_target':pred_test_xgb_model\n",
    "                            ,'CB_target':pred_test_cb_model\n",
    "                            ,'LR_target': pred_test_LR_model\n",
    "                            ,'RFR_target': pred_test_RFR_model\n",
    "                            ,'KN_target': pred_test_KN_model\n",
    "                            ,'3D_target': pred_test_D3_model\n",
    "                            ,'GBR_target': pred_test_GBR_model\n",
    "                            ,'LGB_target': pred_test_lgb_model\n",
    "                            })\n",
    "\n",
    "sub2 = sub.join(new_line)\n",
    "sub2.to_csv('9modealsFinal2024.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of        Unnamed: 0     Price  Sqm  Floor_Level  Built_Year  Bedroom  Bathroom  \\\n",
       "0               0   1540000   30            5        2019      1.0       1.0   \n",
       "1               1   2500000   32            6        2022      1.0       1.0   \n",
       "2               2  14720000   52           12        2012      1.0       1.0   \n",
       "3               3   1490000   30            8        2013      0.5       1.0   \n",
       "4               4   5600000   40           12        2013      1.0       1.0   \n",
       "...           ...       ...  ...          ...         ...      ...       ...   \n",
       "19035       19724   4290000   49           12        1999      1.0       1.0   \n",
       "19036       19725   3590000   50           21        2013      1.0       1.0   \n",
       "19037       19726   6200000   46           28        2012      1.0       1.0   \n",
       "19038       19727   1890000   26            7        2017      1.0       1.0   \n",
       "19039       19728   2600000   30            3        2014      1.0       1.0   \n",
       "\n",
       "       Sub_district  District  Lasso_target   XGB_target     CB_target  \\\n",
       "0            104203      1042  3.702958e+06   1953877.00  2.259364e+06   \n",
       "1            101505      1015  4.740316e+06   2982792.25  5.195232e+06   \n",
       "2            103302      1033  6.198782e+06  10641904.00  1.009076e+07   \n",
       "3            101701      1017  2.740454e+06   2410353.00  2.429135e+06   \n",
       "4            103303      1033  4.256113e+06   5059372.50  5.018223e+06   \n",
       "...             ...       ...           ...          ...           ...   \n",
       "19035        102802      1028           NaN          NaN           NaN   \n",
       "19036        103801      1030           NaN          NaN           NaN   \n",
       "19037        101401      1014           NaN          NaN           NaN   \n",
       "19038        104102      1041           NaN          NaN           NaN   \n",
       "19039        105001      1050           NaN          NaN           NaN   \n",
       "\n",
       "          LR_target    RFR_target  KN_target     3D_target    GBR_target  \\\n",
       "0      3.704185e+06  2.030833e+06  1712000.0  2.530000e+06  2.587739e+06   \n",
       "1      4.742195e+06  3.009000e+06  3940000.0  2.500000e+06  5.518953e+06   \n",
       "2      6.198814e+06  9.894583e+06  6006000.0  9.926667e+06  7.823469e+06   \n",
       "3      2.740651e+06  2.584500e+06  1672000.0  1.710000e+06  2.243113e+06   \n",
       "4      4.256162e+06  4.629800e+06  3592000.0  3.400000e+06  5.257791e+06   \n",
       "...             ...           ...        ...           ...           ...   \n",
       "19035           NaN           NaN        NaN           NaN           NaN   \n",
       "19036           NaN           NaN        NaN           NaN           NaN   \n",
       "19037           NaN           NaN        NaN           NaN           NaN   \n",
       "19038           NaN           NaN        NaN           NaN           NaN   \n",
       "19039           NaN           NaN        NaN           NaN           NaN   \n",
       "\n",
       "         LGB_target  \n",
       "0      2.096764e+06  \n",
       "1      2.834423e+06  \n",
       "2      1.019065e+07  \n",
       "3      2.385875e+06  \n",
       "4      4.983544e+06  \n",
       "...             ...  \n",
       "19035           NaN  \n",
       "19036           NaN  \n",
       "19037           NaN  \n",
       "19038           NaN  \n",
       "19039           NaN  \n",
       "\n",
       "[19040 rows x 18 columns]>"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "sub2.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRICE = sub2[\"Price\"].to_numpy(np.int64)\n",
    "PREDICT = sub2[\"CB_target\"].to_numpy(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0000       0.00      0.00      0.00       3.0\n",
      "            12360000       0.00      0.00      0.00       1.0\n",
      "            12361871       0.00      0.00      0.00       0.0\n",
      "            12370000       0.00      0.00      0.00       1.0\n",
      "            12381696       0.00      0.00      0.00       0.0\n",
      "            12399382       0.00      0.00      0.00       0.0\n",
      "            12400000       0.00      0.00      0.00       3.0\n",
      "            12421071       0.00      0.00      0.00       0.0\n",
      "            12450000       0.00      0.00      0.00       1.0\n",
      "            12480000       0.00      0.00      0.00       1.0\n",
      "            12500000       0.00      0.00      0.00      37.0\n",
      "            12550000       0.00      0.00      0.00       1.0\n",
      "            12600000       0.00      0.00      0.00       3.0\n",
      "            12632873       0.00      0.00      0.00       0.0\n",
      "            12670000       0.00      0.00      0.00       2.0\n",
      "            12700000       0.00      0.00      0.00       3.0\n",
      "            12713450       0.00      0.00      0.00       0.0\n",
      "            12720000       0.00      0.00      0.00       1.0\n",
      "            12730000       0.00      0.00      0.00       1.0\n",
      "            12750000       0.00      0.00      0.00       3.0\n",
      "            12800000       0.00      0.00      0.00      19.0\n",
      "            12802128       0.00      0.00      0.00       0.0\n",
      "            12830000       0.00      0.00      0.00       2.0\n",
      "            12831397       0.00      0.00      0.00       0.0\n",
      "            12834100       0.00      0.00      0.00       0.0\n",
      "            12850000       0.00      0.00      0.00       2.0\n",
      "            12850904       0.00      0.00      0.00       0.0\n",
      "            12877675       0.00      0.00      0.00       0.0\n",
      "            12890000       0.00      0.00      0.00       3.0\n",
      "            12900000       0.00      0.00      0.00      25.0\n",
      "            12941923       0.00      0.00      0.00       0.0\n",
      "            12944730       0.00      0.00      0.00       0.0\n",
      "            12952112       0.00      0.00      0.00       0.0\n",
      "            12960000       0.00      0.00      0.00       2.0\n",
      "            12967000       0.00      0.00      0.00       1.0\n",
      "            12968809       0.00      0.00      0.00       0.0\n",
      "            12980000       0.00      0.00      0.00       3.0\n",
      "            12990000       0.00      0.00      0.00       2.0\n",
      "            12994507       0.00      0.00      0.00       0.0\n",
      "            12999000       0.00      0.00      0.00       1.0\n",
      "            13000000       0.00      0.00      0.00      34.0\n",
      "            13069251       0.00      0.00      0.00       0.0\n",
      "            13070345       0.00      0.00      0.00       0.0\n",
      "            13089184       0.00      0.00      0.00       0.0\n",
      "            13100000       0.00      0.00      0.00       2.0\n",
      "            13126517       0.00      0.00      0.00       0.0\n",
      "            13175511       0.00      0.00      0.00       0.0\n",
      "            13180000       0.00      0.00      0.00       1.0\n",
      "            13196078       0.00      0.00      0.00       0.0\n",
      "            13200000       0.00      0.00      0.00       3.0\n",
      "            13201128       0.00      0.00      0.00       0.0\n",
      "            13247365       0.00      0.00      0.00       0.0\n",
      "            13260000       0.00      0.00      0.00       1.0\n",
      "            13264989       0.00      0.00      0.00       0.0\n",
      "            13285200       0.00      0.00      0.00       1.0\n",
      "            13290000       0.00      0.00      0.00       1.0\n",
      "            13300000       0.00      0.00      0.00       3.0\n",
      "            13328892       0.00      0.00      0.00       0.0\n",
      "            13350000       0.00      0.00      0.00       1.0\n",
      "            13390000       0.00      0.00      0.00       3.0\n",
      "            13400000       0.00      0.00      0.00       7.0\n",
      "            13405499       0.00      0.00      0.00       0.0\n",
      "            13448712       0.00      0.00      0.00       0.0\n",
      "            13450000       0.00      0.00      0.00       1.0\n",
      "            13490000       0.00      0.00      0.00       1.0\n",
      "            13500000       0.00      0.00      0.00      45.0\n",
      "            13592400       0.00      0.00      0.00       0.0\n",
      "            13600000       0.00      0.00      0.00       3.0\n",
      "            13646392       0.00      0.00      0.00       0.0\n",
      "            13732243       0.00      0.00      0.00       0.0\n",
      "            13750000       0.00      0.00      0.00       1.0\n",
      "            13771138       0.00      0.00      0.00       0.0\n",
      "            13790000       0.00      0.00      0.00       1.0\n",
      "            13800000       0.00      0.00      0.00       4.0\n",
      "            13835270       0.00      0.00      0.00       0.0\n",
      "            13870000       0.00      0.00      0.00       1.0\n",
      "            13880000       0.00      0.00      0.00       2.0\n",
      "            13880098       0.00      0.00      0.00       0.0\n",
      "            13900000       0.00      0.00      0.00      12.0\n",
      "            13933073       0.00      0.00      0.00       0.0\n",
      "            13950000       0.00      0.00      0.00       1.0\n",
      "            13979947       0.00      0.00      0.00       0.0\n",
      "            13990000       0.00      0.00      0.00       2.0\n",
      "            14000000       0.00      0.00      0.00      39.0\n",
      "            14025457       0.00      0.00      0.00       0.0\n",
      "            14040000       0.00      0.00      0.00       1.0\n",
      "            14049362       0.00      0.00      0.00       0.0\n",
      "            14085356       0.00      0.00      0.00       0.0\n",
      "            14100000       0.00      0.00      0.00       1.0\n",
      "            14120000       0.00      0.00      0.00       1.0\n",
      "            14186919       0.00      0.00      0.00       0.0\n",
      "            14200000       0.00      0.00      0.00       2.0\n",
      "            14239854       0.00      0.00      0.00       0.0\n",
      "            14251532       0.00      0.00      0.00       0.0\n",
      "            14272458       0.00      0.00      0.00       0.0\n",
      "            14300000       0.00      0.00      0.00       4.0\n",
      "            14343593       0.00      0.00      0.00       0.0\n",
      "            14490000       0.00      0.00      0.00       4.0\n",
      "            14500000       0.00      0.00      0.00      12.0\n",
      "            14552275       0.00      0.00      0.00       0.0\n",
      "            14590998       0.00      0.00      0.00       0.0\n",
      "            14600000       0.00      0.00      0.00       2.0\n",
      "            14620000       0.00      0.00      0.00       1.0\n",
      "            14650000       0.00      0.00      0.00       1.0\n",
      "            14690000       0.00      0.00      0.00       1.0\n",
      "            14700000       0.00      0.00      0.00       6.0\n",
      "            14700001       0.00      0.00      0.00       1.0\n",
      "            14700009       0.00      0.00      0.00       1.0\n",
      "            14720000       0.00      0.00      0.00       1.0\n",
      "            14730000       0.00      0.00      0.00       1.0\n",
      "            14750000       0.00      0.00      0.00       1.0\n",
      "            14788518       0.00      0.00      0.00       0.0\n",
      "            14795890       0.00      0.00      0.00       0.0\n",
      "            14800000       0.00      0.00      0.00       4.0\n",
      "            14807326       0.00      0.00      0.00       0.0\n",
      "            14850000       0.00      0.00      0.00       1.0\n",
      "            14878103       0.00      0.00      0.00       0.0\n",
      "            14900000       0.00      0.00      0.00      31.0\n",
      "            14907847       0.00      0.00      0.00       0.0\n",
      "            14940000       0.00      0.00      0.00       1.0\n",
      "            14950000       0.00      0.00      0.00       1.0\n",
      "            14957978       0.00      0.00      0.00       0.0\n",
      "            14990000       0.00      0.00      0.00       1.0\n",
      "            15000000       0.00      0.00      0.00      29.0\n",
      "            15057283       0.00      0.00      0.00       0.0\n",
      "            15106986       0.00      0.00      0.00       0.0\n",
      "            15140893       0.00      0.00      0.00       0.0\n",
      "            15165813       0.00      0.00      0.00       0.0\n",
      "            15200000       0.00      0.00      0.00       3.0\n",
      "            15265000       0.00      0.00      0.00       2.0\n",
      "            15300000       0.00      0.00      0.00       5.0\n",
      "            15390276       0.00      0.00      0.00       0.0\n",
      "            15400000       0.00      0.00      0.00       4.0\n",
      "            15419588       0.00      0.00      0.00       0.0\n",
      "            15424000       0.00      0.00      0.00       1.0\n",
      "            15500000       0.00      0.00      0.00      16.0\n",
      "            15512994       0.00      0.00      0.00       0.0\n",
      "            15533980       0.00      0.00      0.00       1.0\n",
      "            15580000       0.00      0.00      0.00       1.0\n",
      "            15600000       0.00      0.00      0.00       1.0\n",
      "            15678802       0.00      0.00      0.00       0.0\n",
      "            15700000       0.00      0.00      0.00       3.0\n",
      "            15750000       0.00      0.00      0.00       4.0\n",
      "            15766181       0.00      0.00      0.00       0.0\n",
      "            15800000       0.00      0.00      0.00       7.0\n",
      "            15827044       0.00      0.00      0.00       0.0\n",
      "            15870000       0.00      0.00      0.00       1.0\n",
      "            15890000       0.00      0.00      0.00       3.0\n",
      "            15896074       0.00      0.00      0.00       0.0\n",
      "            15900000       0.00      0.00      0.00       9.0\n",
      "            15917888       0.00      0.00      0.00       0.0\n",
      "            15970000       0.00      0.00      0.00       1.0\n",
      "            15975317       0.00      0.00      0.00       0.0\n",
      "            15990000       0.00      0.00      0.00       1.0\n",
      "            16000000       0.00      0.00      0.00       8.0\n",
      "            16100000       0.00      0.00      0.00       1.0\n",
      "            16200000       0.00      0.00      0.00       3.0\n",
      "            16300000       0.00      0.00      0.00       1.0\n",
      "            16390000       0.00      0.00      0.00       1.0\n",
      "            16400000       0.00      0.00      0.00       2.0\n",
      "            16490000       0.00      0.00      0.00       1.0\n",
      "            16500000       0.00      0.00      0.00      14.0\n",
      "            16590000       0.00      0.00      0.00       2.0\n",
      "            16600000       0.00      0.00      0.00       1.0\n",
      "            16640000       0.00      0.00      0.00       1.0\n",
      "            16671729       0.00      0.00      0.00       0.0\n",
      "            16685916       0.00      0.00      0.00       0.0\n",
      "            16719292       0.00      0.00      0.00       0.0\n",
      "            16777578       0.00      0.00      0.00       0.0\n",
      "            16790000       0.00      0.00      0.00       1.0\n",
      "            16800000       0.00      0.00      0.00       1.0\n",
      "            16850000       0.00      0.00      0.00       1.0\n",
      "            16900000       0.00      0.00      0.00       7.0\n",
      "            16916641       0.00      0.00      0.00       0.0\n",
      "            17000000       0.00      0.00      0.00      13.0\n",
      "            17100000       0.00      0.00      0.00       2.0\n",
      "            17250000       0.00      0.00      0.00       1.0\n",
      "            17279000       0.00      0.00      0.00       1.0\n",
      "            17337470       0.00      0.00      0.00       0.0\n",
      "            17359200       0.00      0.00      0.00       0.0\n",
      "            17397451       0.00      0.00      0.00       0.0\n",
      "            17400000       0.00      0.00      0.00       1.0\n",
      "            17500000       0.00      0.00      0.00      15.0\n",
      "            17600000       0.00      0.00      0.00       1.0\n",
      "            17643445       0.00      0.00      0.00       0.0\n",
      "            17700000       0.00      0.00      0.00       2.0\n",
      "            17800000       0.00      0.00      0.00       3.0\n",
      "            17800009       0.00      0.00      0.00       1.0\n",
      "            17900000       0.00      0.00      0.00       5.0\n",
      "            17990000       0.00      0.00      0.00       1.0\n",
      "            18000000       0.00      0.00      0.00       7.0\n",
      "            18200000       0.00      0.00      0.00       1.0\n",
      "            18300000       0.00      0.00      0.00       1.0\n",
      "            18303902       0.00      0.00      0.00       0.0\n",
      "            18331523       0.00      0.00      0.00       0.0\n",
      "            18490000       0.00      0.00      0.00       3.0\n",
      "            18494193       0.00      0.00      0.00       0.0\n",
      "            18500000       0.00      0.00      0.00       4.0\n",
      "            18600000       0.00      0.00      0.00       4.0\n",
      "            18760881       0.00      0.00      0.00       0.0\n",
      "            18800000       0.00      0.00      0.00       1.0\n",
      "            18830854       0.00      0.00      0.00       0.0\n",
      "            18900000       0.00      0.00      0.00       1.0\n",
      "            19000000       0.00      0.00      0.00      15.0\n",
      "            19050000       0.00      0.00      0.00       1.0\n",
      "            19100000       0.00      0.00      0.00       2.0\n",
      "            19136301       0.00      0.00      0.00       0.0\n",
      "            19198758       0.00      0.00      0.00       0.0\n",
      "            19200000       0.00      0.00      0.00       2.0\n",
      "            19290000       0.00      0.00      0.00       1.0\n",
      "            19300000       0.00      0.00      0.00       1.0\n",
      "            19400000       0.00      0.00      0.00       5.0\n",
      "            19500000       0.00      0.00      0.00       3.0\n",
      "            19600000       0.00      0.00      0.00       1.0\n",
      "            19800000       0.00      0.00      0.00       2.0\n",
      "            19825043       0.00      0.00      0.00       0.0\n",
      "            19900000       0.00      0.00      0.00       4.0\n",
      "            20000000       0.00      0.00      0.00      11.0\n",
      "            20085000       0.00      0.00      0.00       1.0\n",
      "            20300000       0.00      0.00      0.00       2.0\n",
      "            20306723       0.00      0.00      0.00       0.0\n",
      "            20409079       0.00      0.00      0.00       0.0\n",
      "            20500000       0.00      0.00      0.00       1.0\n",
      "            20600000       0.00      0.00      0.00       2.0\n",
      "            20700000       0.00      0.00      0.00       1.0\n",
      "            20800000       0.00      0.00      0.00       5.0\n",
      "            20872438       0.00      0.00      0.00       0.0\n",
      "            20900000       0.00      0.00      0.00       1.0\n",
      "            21000000       0.00      0.00      0.00       4.0\n",
      "            21189355       0.00      0.00      0.00       0.0\n",
      "            21300000       0.00      0.00      0.00       3.0\n",
      "            21334849       0.00      0.00      0.00       0.0\n",
      "            21382602       0.00      0.00      0.00       0.0\n",
      "            21386417       0.00      0.00      0.00       0.0\n",
      "            21500000       0.00      0.00      0.00       1.0\n",
      "            21634000       0.00      0.00      0.00       1.0\n",
      "            21700000       0.00      0.00      0.00       3.0\n",
      "            21800000       0.00      0.00      0.00       1.0\n",
      "            21816709       0.00      0.00      0.00       0.0\n",
      "            21900000       0.00      0.00      0.00       2.0\n",
      "            21903759       0.00      0.00      0.00       0.0\n",
      "            22000000       0.00      0.00      0.00       9.0\n",
      "            22014403       0.00      0.00      0.00       0.0\n",
      "            22050000       0.00      0.00      0.00       1.0\n",
      "            22250000       0.00      0.00      0.00       1.0\n",
      "            22600000       0.00      0.00      0.00       1.0\n",
      "            22800000       0.00      0.00      0.00       2.0\n",
      "            22800001       0.00      0.00      0.00       1.0\n",
      "            22800009       0.00      0.00      0.00       1.0\n",
      "            22880000       0.00      0.00      0.00       1.0\n",
      "            23000000       0.00      0.00      0.00       6.0\n",
      "            23500000       0.00      0.00      0.00       1.0\n",
      "            23650000       0.00      0.00      0.00       1.0\n",
      "            23667661       0.00      0.00      0.00       0.0\n",
      "            23700000       0.00      0.00      0.00       5.0\n",
      "            23900000       0.00      0.00      0.00       1.0\n",
      "            24000000       0.00      0.00      0.00       3.0\n",
      "            24294252       0.00      0.00      0.00       0.0\n",
      "            24368874       0.00      0.00      0.00       0.0\n",
      "            24382134       0.00      0.00      0.00       0.0\n",
      "            24500000       0.00      0.00      0.00       1.0\n",
      "            24900000       0.00      0.00      0.00       1.0\n",
      "            25000000       0.00      0.00      0.00      10.0\n",
      "            25176000       0.00      0.00      0.00       7.0\n",
      "            25196270       0.00      0.00      0.00       0.0\n",
      "            25500000       0.00      0.00      0.00       2.0\n",
      "            25750000       0.00      0.00      0.00       3.0\n",
      "            25900000       0.00      0.00      0.00       1.0\n",
      "            25990000       0.00      0.00      0.00       1.0\n",
      "            26268170       0.00      0.00      0.00       0.0\n",
      "            26400000       0.00      0.00      0.00       1.0\n",
      "            26500000       0.00      0.00      0.00       8.0\n",
      "            26800000       0.00      0.00      0.00       1.0\n",
      "            26880859       0.00      0.00      0.00       0.0\n",
      "            27000000       0.00      0.00      0.00      16.0\n",
      "            27300000       0.00      0.00      0.00       1.0\n",
      "            27335000       0.00      0.00      0.00       2.0\n",
      "            27500000       0.00      0.00      0.00       1.0\n",
      "            28000000       0.00      0.00      0.00       2.0\n",
      "            28500000       0.00      0.00      0.00       1.0\n",
      "            28680000       0.00      0.00      0.00       1.0\n",
      "            28700000       0.00      0.00      0.00       1.0\n",
      "            29000000       0.00      0.00      0.00       8.0\n",
      "            29900000       0.00      0.00      0.00       2.0\n",
      "            30000000       0.00      0.00      0.00       1.0\n",
      "            30900000       0.00      0.00      0.00       5.0\n",
      "            31000000       0.00      0.00      0.00       2.0\n",
      "            31500000       0.00      0.00      0.00       1.0\n",
      "            31776602       0.00      0.00      0.00       0.0\n",
      "            31900000       0.00      0.00      0.00       1.0\n",
      "            32444053       0.00      0.00      0.00       0.0\n",
      "            33000000       0.00      0.00      0.00       2.0\n",
      "            33037499       0.00      0.00      0.00       0.0\n",
      "            33500000       0.00      0.00      0.00       1.0\n",
      "            34000000       0.00      0.00      0.00       1.0\n",
      "            35020000       0.00      0.00      0.00       1.0\n",
      "            35500000       0.00      0.00      0.00       4.0\n",
      "            35540000       0.00      0.00      0.00       1.0\n",
      "            37500000       0.00      0.00      0.00       1.0\n",
      "            37900000       0.00      0.00      0.00       1.0\n",
      "            38000000       0.00      0.00      0.00       3.0\n",
      "            39500000       0.00      0.00      0.00       1.0\n",
      "            39900000       0.00      0.00      0.00       6.0\n",
      "            40000000       0.00      0.00      0.00       1.0\n",
      "            41000000       0.00      0.00      0.00       1.0\n",
      "            41900000       0.00      0.00      0.00       1.0\n",
      "            46000000       0.00      0.00      0.00       2.0\n",
      "            46500000       0.00      0.00      0.00       4.0\n",
      "            50000000       0.00      0.00      0.00       1.0\n",
      "            56500000       0.00      0.00      0.00       1.0\n",
      "            62000000       0.00      0.00      0.00       1.0\n",
      "            63700000       0.00      0.00      0.00       1.0\n",
      "\n",
      "            accuracy                           0.00   19040.0\n",
      "           macro avg       0.00      0.00      0.00   19040.0\n",
      "        weighted avg       0.00      0.00      0.00   19040.0\n",
      "\n",
      "C:\\Users\\Nutcl\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Nutcl\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(PRICE,PREDICT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "rms = sqrt(mean_squared_error(PRICE, PREDICT))\n",
    "print (rms)"
   ]
  }
 ]
}